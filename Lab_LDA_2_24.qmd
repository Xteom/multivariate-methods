---
title: "Clasificación: LDA 2"
lang: es
author: "Jorge de la Vega"
date: "`r Sys.Date()`"
format: 
  html:
    page-layout: full
    html-math-method: katex
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Datos iris de Fisher

-   Los datos consisten en mediciones de $p=4$ variables tomadas de $n_k=50$ flores en cada uno de los $g=3$ especies o grupos:
    -   longitud del sépalo
    -   ancho del sépalo
    -   longitud del pétalo
    -   ancho del pétalo

![Características de Iris](/home/jvega/Dropbox/Efigs/irisflor.png)

-   El objetivo es crear una función discriminante que mejor clasifique una nueva flor en una de las tres especies.

```{r}
head(iris)
```

Ajustando un modelo discriminante con `lda` del paquete `MASS`:

```{r}
library(MASS)
(lda1 <- lda(Species ~ ., data = iris, prior = rep(1/3,3)))
#tenemos las proyecciones de una sobre la otra
```

Consideraciones al cálculo realizado:

1.  Cada variable del conjunto de datos se transforma para **esferizarlos**: se reescala para que las componentes principales tengan varianza unitaria, de tal manera que la matriz de varianzas de las CPs se vuelva la identidad

2.  los scores de los discriminantes están escalados para que promedien 0.

3.  El número de discriminantes lineales corresponde al rango de la matriz ${\bf B} = r = min(g-1,p)$

```{r}
plot(lda1) #como se ven en la proyección lineal
plot(lda1, dimen = 1) # primer discriminante, proyecciones sobre los ejes
plot(lda1, type = "density", dimen = 1, #
     main = "Desidades estimadas de los grupos") # primera dimensión
```

```{r}
library(klaR)

especies <- iris[,5]
partimat(x=iris[,-5], grouping = especies, method="lda")
```


## Clasificación de cangrejos

Los datos corresponden a 200 especímenes de cangrejos *Leptograpsus variegatus* en la costa de Australia occidental. Ocurren en dos formas de colores: azules y naranjas, y se juntaron 50 de cada forma de cada sexo y se hicieron 5 medidas físicas:

-   `CL`: longitud del caparazón.
-   `CW`: ancho del caparazón
-   `FL`: tamaño del lóbulo frontal
-   `RW`: ancho trasero
-   `BD`: Profundidad del cuerpo.

Parte de la tesis de los autores de la investigación fue establecer que las dos formas de colores eran claramente diferenciables morfológicamente, para justificar la clasificación como dos especies separadas.

```{r}
summary(crabs)
```

Queremos contruir una regla de clasificación para predecir el sexo de un cangrejo futuro *Leptograpsus* de forma de color desconocido.

![Leptograpsus variegata](/home/jvega/Dropbox/Efigs/Leptograpsus.jpg) Para este ejercicio se ignorará la variable `BD` porque se mide de manera diferente para hembras y machos.

```{r}
(crabs.lda <- lda(sex ~ FL + RW + CL + CW, data = crabs, method = "t"))
```

Para ver cómo se clasificaron los valores usando todos los datos, obtenemos la matriz de confusión.

```{r}
table(crabs$sex, predict(crabs.lda)$class)
```

Tomando en cuenta el color (especie) se crea una variable que hace la interacción entre sexo y color.

```{r}
crabs.grp <- interaction(crabs$sp,crabs$sex)
(crabs.lda2 <- lda(crabs.grp ~ FL + RW + CL + CW, data = crabs))
```

Haciendo la predicción usando sólo dos dimensiones:

```{r}
prediccion <- predict(crabs.lda2, dimen = 2)
# Agrega las probabilidades posteriores para machos de los dos colores.
probs <- prediccion$posterior[,c("B.M","O.M")] %*% c(1,1) 
table(crabs$sex, probs > 0.5)

```

Usando los primeros dos discriminantes lineales se obtiene una buena aproximación de las regiones de decisión

```{r}
# scores en los dos discriminantes lineales
scores <- prediccion$x[,1:2] 
# grafica con escalas iguales en los dos ejes
eqscplot(scores, type = "n", xlab = "LDA1", ylab = "LDA2")
text(scores, labels = crabs.grp, col = as.numeric(as.factor(crabs.grp)))

# la siguiente función grafica la linea perpendicular 
perp <- function(x,y){
  m <- (x+y)/2
  s <- -(x[1]-y[1])/(x[2]-y[2])
  abline(c(m[2]-s*m[1], s))
}

# obten discriminante sólo en sexo
cr.m <- lda(scores, crabs$sex)$means
points(cr.m, pch = 3, col = "red", cex = 2)
perp(cr.m[1,],cr.m[2,])
```

En la función `lda`, se pueden usar estimadores robustos de la varianza intraclases ${\bf W}$, ya que los métodos pueden ser muy sensibles a outliers. Se tienen varias opciones de estimación:

-   `method = "mve"` utiliza un elipsoide de volumen mínimo.
-   `method = "t"` utiliza una distribución $t$ con pocos grados de libertad (por default $\nu=5$)

# Evaluación de reglas de clasificación: forma manual

1.  Obtenemos los conjuntos de entrenamiento y prueba

```{r}
Fem <- subset(crabs, sex == "F")
Mal <- subset(crabs, sex == "M")
indF <- sample.int(n = 100, size = 70)
indM <- sample.int(n = 100, size = 70)
crabs.train <- rbind(Fem[indF,], Mal[indM,])
crabs.test <- rbind(Fem[-indF,], Mal[-indM,])
```

```{r}
ldatrain <- lda(sex ~ FL + RW + CL + CW, data = crabs.train, prior = c(0.5,0.5))
(confusionTest <- table(crabs.test$sex, predict(ldatrain, newdata = crabs.test)$class))
n <- sum(confusionTest)
(aer <- (n-sum(diag(confusionTest)))/n)
```

Aplicamos validación cruzada de dos hojas con 100 splits 70/30

```{r}
numrep <- 100
aer <- rep(0,numrep)
set.seed(1)
for(k in 1:numrep){
  # reptios la partición
  indF <- sample.int(n = 100, size = 70)
  indM <- sample.int(n = 100, size = 70)
  crabs.train <- rbind(Fem[indF,], Mal[indM,])
  crabs.test <- rbind(Fem[-indF,], Mal[-indM,])
  qdatrain <- lda(sex ~ FL + RW + CL + CW, data = crabs.train, prior = c(0.5,0.5))
  confusionTest <- table(crabs.test$sp, predict(qdatrain, newdata = crabs.test)$class)
  confusionTest
  n <- sum(confusionTest)
  aer[k] <- (n - sum(diag(confusionTest))) / n
}
```

# Evaluación automatizada con `caret`

Utilicemos discriminación lineal y cuadrática para comparar cuál modelo tiene mayor poder predictivo. El paquete `caret` puede ayudar a establecer el setup para validación cruzada y comparación de modelos.

Una guía completa para este paquete se encuentra en: <https://topepo.github.io/caret/index.html>

```{r}
library(caret)
#genera los indices para ver cuales van en train
ind_val <- createDataPartition(crabs$sex, p = 0.7, list = F) # tomamos 70% de los datos para entrenamiento
crab_train <- crabs[ind_val,]
crab_test <- crabs[-ind_val,]
```

Vamos a usar validacion cruzada de 10 hojas para estimar lo adecuado del modelo: Esto divide los datos en 10 partes, entrena en 9 y prueba en 1 y nos da resultados para todas las combinaciones de entrenamiento-prueba

```{r}
control <- trainControl(method = "repeatedcv", #puede se solo cv y no repite
                        number = 10,
                        repeats = 10,
                        classProbs = T, 
                        preProc = c("center", "scaling"))
metrica <- "Accuracy"
```

Consideremos los modelos

```{r}
set.seed(1234)
fit.lda <- train(sex ~ FL + RW + CL + CW, 
                 data = crab_train,
                 method = "lda", 
                 metric = metrica,
                 trControl = control)
set.seed(1234)
fit.qda <- train(sex ~ FL + RW + CL + CW + BD, 
                 data = crab_train,
                 method = "qda", 
                 metric = metrica,
                 trControl = control)
# Kappa de cohen : estadística no poderada que mide la coicidencia entre 2 clasificadores 
# con N items en C categorías 
# k = 1 completamente de acuerdo 
# k = 0 el acuerdo se da por azar 
# k < 0 tienden a clasificar de manera ñ
```

$$
k=\frac{2(TP \cdot TN - FP \cdot FN)}{(TP+FP)\cdot(FP + TN) + (TN + FN) \cdot (FN + TN)}
$$
Resumimos el resultado de los modelos

```{r}
resultados <- resamples(list(lda = fit.lda,
                             qda = fit.qda))
summary(resultados)
dotplot(resultados)
```

Podemos ahora hacer predicciones:

```{r}
# Para el discriminante lineal
prediccion.lda <- predict(fit.lda, crab_test)
confusionMatrix(prediccion.lda, crab_test$sex)

# Para el discriminante cuadrático
prediccion.qda <- predict(fit.qda, crab_test)
confusionMatrix(prediccion.qda, crab_test$sex)

```
